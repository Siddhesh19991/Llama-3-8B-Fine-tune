{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-18T15:32:11.122814Z","iopub.status.busy":"2024-07-18T15:32:11.122231Z","iopub.status.idle":"2024-07-18T15:36:31.947589Z","shell.execute_reply":"2024-07-18T15:36:31.946306Z","shell.execute_reply.started":"2024-07-18T15:32:11.122784Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!mamba install --force-reinstall aiohttp -y\n","!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n","!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n","\n","# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n","!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n","\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"markdown","metadata":{},"source":["Loading the base model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T15:36:37.647761Z","iopub.status.busy":"2024-07-18T15:36:37.647399Z","iopub.status.idle":"2024-07-18T15:37:31.186806Z","shell.execute_reply":"2024-07-18T15:37:31.185798Z","shell.execute_reply.started":"2024-07-18T15:36:37.647731Z"},"trusted":true},"outputs":[],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 \n","dtype = None # None for auto detection\n","load_in_4bit = True # 4bit quantization\n","\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\", \n","    max_seq_length = max_seq_length, \n","    dtype = dtype, \n","    load_in_4bit = load_in_4bit\n",")"]},{"cell_type":"markdown","metadata":{},"source":["We now add LoRA adapters so we only need to update a percentage of all parameters depending on \"r\". \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T15:37:31.188975Z","iopub.status.busy":"2024-07-18T15:37:31.188382Z","iopub.status.idle":"2024-07-18T15:37:36.106255Z","shell.execute_reply":"2024-07-18T15:37:36.105157Z","shell.execute_reply.started":"2024-07-18T15:37:31.188947Z"},"trusted":true},"outputs":[],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, #Used 8 \n","    # The rank “r” is a user parameter, the less number of parameters to train and bigger the savings on compute.  \n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 32, # amount of weightage of Lora weights on the base model \n","    lora_dropout = 0, \n","    bias = \"none\",   \n","    use_gradient_checkpointing = \"unsloth\", \n","    random_state = 3407,\n","    use_rslora = False,  # rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Loading the data, splitting it into test-train and structuring it in the right format for the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T15:37:36.108582Z","iopub.status.busy":"2024-07-18T15:37:36.107774Z","iopub.status.idle":"2024-07-18T15:37:40.397880Z","shell.execute_reply":"2024-07-18T15:37:40.396965Z","shell.execute_reply.started":"2024-07-18T15:37:36.108547Z"},"trusted":true},"outputs":[],"source":["medical_prompt = \"\"\"You are a medical expert providing accurate and relevant answers to medical inquiries based on your specialized knowledge. Always start your answer saying \"Hello, welcome to the medical chat forum,\"\n","\n","### Example-1: \n","\n","**Input:**  Hello doctor,My friend aged 30 had two drops of phenol mistaking for milk. He vomited and had lot of salt water. Please advice for any side effect.\n","\n","**Response:**  1. The side effects of phenol include irritation to the eyes, skin rashes, increased heart rate, respiratory depression, nausea, dizziness, headache, sweating, tremors, seizures, coma, and even death.2. Since your friend has already taken it, he should be fine. There is no need to worry about any long-term damage.3. However, if he develops symptoms such as rapid breathing, low blood pressure, chest pain or discomfort, confusion, extreme sleepiness, irregular heartbeats, severe headaches, or vomiting, then he needs immediate medical attention. Hope I have answered your query. Let me know if I can assist you further.\n","\n","### Example-2: \n","\n","**Input:** Hi doctor,I have been treated with for a yeast infection and given antibiotics last month end and then last week had another infection (milky like discharge no smell). Is it advisable to wait for one month to be seen by my gynecologist or go to an urgent care right away?\n","\n","**Response:** 1) yeast infections can occur again if not cured properly.2) It is better to get examined by your doctor and take proper treatment at the earliest to avoid complications.3) You may also need blood tests such as CBC, ESR, FBS, PPS, etc., as well as culture and sensitivity test of the vaginal swab to confirm the diagnosis.4) The best way to prevent recurrent yeast infections is to keep the area clean and Chat Doctor. 5) Avoid wearing tight-fitting panties, especially those made of synthetic materials.6) Take more of probiotic food items like yogurt, buttermilk, curd, etc.\n","\n","### Example-3: \n","\n","**Input:** Hello doctor,I have spastic paraplegia. Everything I have tried has not worked. I was told to try a medication called L-Dopa. Will this medication help me?\n","\n","**Response:** 1) Dopamine is a chemical in the brain that helps nerve cells send signals. It also helps control movement. L-dopa is converted into dopamine in the body and can be used for treating Parkinsonism (which includes tremors, stiffness, slow movements and muscle rigidity).2) Yes, it will help you. But there are certain precautions to take while using it as follows:1) Do not use if you are allergic to any of its ingredients. 2) Avoid alcohol when taking this medicine.3) Take with food or milk to avoid stomach upset.4) You may need to increase your dose slowly over time.5) This medicine may cause dizziness, lightheadedness, or fainting. Do not drive, operate machinery, or do other dangerous activities until you know how this medicine affects you.\n","\n","#####\n","Follow the following rule:\n","- Always start your answer saying \"Hello, welcome to the medical chat forum,\"\n","- Do not say \"Hello, welcome to Chat Doctor forum\", \"Hi, welcome to Chat Doctor forum\", or \"I am Chat Doctor\" in your answer. \n","- Provide your answer in numbered points.\n","\n","\n","### Input:\n","{}\n","\n","\n","### Response:\n"," {}\n","\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    #instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"answer_chatdoctor\"]\n","    texts = []\n","    for input, output in zip(inputs, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = medical_prompt.format(input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","\n","from datasets import load_dataset, DatasetDict, Dataset\n","from sklearn.model_selection import train_test_split\n","\n","dataset = load_dataset(\"Sid404/medical_data\", split = \"train\")\n","\n","df = dataset.to_pandas()\n","\n","# Split the DataFrame into training and testing sets\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Convert the DataFrames back to Dataset objects\n","train_dataset = Dataset.from_pandas(train_df)\n","test_dataset = Dataset.from_pandas(test_df)\n","\n","train_dataset = train_dataset.map(formatting_prompts_func, batched = True)\n","test_dataset = test_dataset.map(formatting_prompts_func, batched = True)"]},{"cell_type":"markdown","metadata":{},"source":["Training parameters "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T15:37:40.400171Z","iopub.status.busy":"2024-07-18T15:37:40.399868Z","iopub.status.idle":"2024-07-18T15:37:55.560612Z","shell.execute_reply":"2024-07-18T15:37:55.559601Z","shell.execute_reply.started":"2024-07-18T15:37:40.400139Z"},"trusted":true},"outputs":[],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_dataset,\n","    dataset_text_field = \"text\",\n","    eval_dataset = test_dataset, \n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, \n","    args = TrainingArguments(\n","        per_device_train_batch_size = 1,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        num_train_epochs=1,\n","        learning_rate = 4e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\",\n","        save_strategy = \"steps\",\n","        save_steps = 1/16 #Checkpoints \n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-18T16:02:43.101194Z","iopub.status.busy":"2024-07-18T16:02:43.100893Z","iopub.status.idle":"2024-07-18T17:03:31.359903Z","shell.execute_reply":"2024-07-18T17:03:31.358892Z","shell.execute_reply.started":"2024-07-18T16:02:43.101167Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-18T10:07:28.302377Z","iopub.status.busy":"2024-07-18T10:07:28.301986Z","iopub.status.idle":"2024-07-18T10:07:36.135721Z","shell.execute_reply":"2024-07-18T10:07:36.134442Z","shell.execute_reply.started":"2024-07-18T10:07:28.302336Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["eval_stats = trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["Manual Inference: "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T17:05:58.627990Z","iopub.status.busy":"2024-07-18T17:05:58.627637Z","iopub.status.idle":"2024-07-18T17:06:09.556716Z","shell.execute_reply":"2024-07-18T17:06:09.555933Z","shell.execute_reply.started":"2024-07-18T17:05:58.627962Z"},"trusted":true},"outputs":[],"source":["FastLanguageModel.for_inference(model) \n","inputs = tokenizer(\n","[\n","    medical_prompt.format(\n","        \"Hello doctor, I have acne scars. What medical treatments should I use?\",  # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 150, use_cache = True)\n","text = tokenizer.batch_decode(outputs)\n","parts = text[0].split(\"### Response:\")\n","\n","# Get the response part and clean it\n","response = parts[1].split(\"### Input:\")[0].strip()"]},{"cell_type":"markdown","metadata":{},"source":["Now we shall evalute how this fine-tuned model performs on the test data. "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-18T17:06:30.568978Z","iopub.status.busy":"2024-07-18T17:06:30.568083Z","iopub.status.idle":"2024-07-18T20:45:42.983505Z","shell.execute_reply":"2024-07-18T20:45:42.982678Z","shell.execute_reply.started":"2024-07-18T17:06:30.568944Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["fine_tuned = []\n","\n","for i in range(len(test_dataset[\"text\"])):\n","    print(i)\n","    inputs = tokenizer(\n","[\n","    medical_prompt.format(\n","        test_dataset[\"input\"][i], # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens = 250, use_cache = True)\n","    text = tokenizer.batch_decode(outputs)\n","    parts = text[0].split(\"### Response:\")\n","\n","    # Get the response part and clean it\n","    fine_tuned.append(parts[1].split(\"### Input:\")[0].strip())\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Using BERTScore and BLEUscore to evaluate its performance (Fine-tuned Model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import statistics\n","from evaluate import load\n","bertscore = load(\"bertscore\")\n","results_1 = bertscore.compute(\n","    predictions=fine_tuned, references=test_dataset[\"answer_chatdoctor\"], lang=\"en\")\n","\n","\n","print(statistics.mean(results_1[\"precision\"]))\n","print(statistics.mean(results_1[\"recall\"]))\n","print(statistics.mean(results_1[\"f1\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bleu = load(\"bleu\")\n","results_2 = bleu.compute(predictions=fine_tuned,\n","                         references=test_dataset[\"answer_chatdoctor\"])"]},{"cell_type":"markdown","metadata":{},"source":["Loading the base model to compare its responses for the test data with the fine-tuned responses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T17:44:10.268493Z","iopub.status.busy":"2024-07-17T17:44:10.267597Z","iopub.status.idle":"2024-07-17T17:44:20.059781Z","shell.execute_reply":"2024-07-17T17:44:20.058732Z","shell.execute_reply.started":"2024-07-17T17:44:10.268458Z"},"trusted":true},"outputs":[],"source":["model_base, tokenizer_base = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\", \n","    max_seq_length = max_seq_length, \n","    dtype = dtype, \n","    load_in_4bit = load_in_4bit #4-bit quantization\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base = []\n","\n","for i in range(len(test_dataset[\"text\"])):\n","    print(i)\n","    inputs = tokenizer(\n","[\n","    medical_prompt.format(\n","        test_dataset[\"input\"][i], # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n","    text = tokenizer.batch_decode(outputs)\n","    parts = text[0].split(\"### Response:\")\n","\n","    # Get the response part and clean it\n","    base.append(parts[1].split(\"### Input:\")[0].strip())"]},{"cell_type":"markdown","metadata":{},"source":["Using BERTScore and BLEUscore to evaluate its performance (Base Model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-18T20:53:28.769654Z","iopub.status.busy":"2024-07-18T20:53:28.768964Z","iopub.status.idle":"2024-07-18T20:53:28.775620Z","shell.execute_reply":"2024-07-18T20:53:28.774764Z","shell.execute_reply.started":"2024-07-18T20:53:28.769621Z"},"trusted":true},"outputs":[],"source":["results_1_base = bertscore.compute(\n","    predictions=base, references=test_dataset[\"answer_chatdoctor\"], lang=\"en\")\n","\n","\n","print(statistics.mean(results_1_base[\"precision\"]))\n","print(statistics.mean(results_1_base[\"recall\"]))\n","print(statistics.mean(results_1_base[\"f1\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bleu = load(\"bleu\")\n","results_2_base = bleu.compute(predictions=base,\n","                         references=test_dataset[\"answer_chatdoctor\"])"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
